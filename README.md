# taobao-business-opportunity-crawler
本项目是一个爬虫程序，针对淘宝'下游商机'的网页进行爬取，获取了电商的商品数据
  
**输出结果**
```
| 一级类目(女装_女士精品)
├───── 二级类目(毛呢外套)
├──────────三级类目(毛呢外套.xlsx)
├── 二级类目(中老年女装)
├──────────三级类目(中老年女装.xlsx)
| 一级类目
├── 二级类目
├── 二级类目
... ...
```



**项目结构**
```
taobao-business-opportunity-crawler/
├── chromedriver-win64/         # ChromeDriver 驱动文件，用于 Selenium 自动化
├── main.py                     # 项目主入口，用于调度整个爬虫流程
├── config.py                   # 配置文件，可调节时间范畴，爬取榜单，多进程的数量，是否有头 等
├── crawler.py                  # 爬取商机链接和对应图像链接模块，使用爬取链接和解析链接两步进行提高效率
├── pipeline.py                 # 图片链接解析模块，商机链接解析模块
├── final_process.py            # 最后格式处理，并根据爬取的数据计算新指标
├── 一级类目.xlsx               # 初始输入文件，包含待爬取链接或类目信息，可多选多个一级目录
├── README.md                   # 项目说明文档
```
  
**配置文件介绍**
```
"""
config.py：提供大量请求头，防止平台检测到爬虫程序，从而拒绝服务
"""
# ——————————————————————————————————————————————————————

time_range = "7" # 人为设置需要爬取的时间，另一个值是设置为7
# 参考 可改成 ： time_range = "7"

category = "热销榜" # 人为设置‘热搜榜’，‘飙升榜’，‘热销榜’
# 参考 可改成 ： category = "飙升榜"
# 参考 可改成 ： category = "热销榜"

processing_quantity = 2 # 多进程的数量，控制爬取速度，最好与网速和cpu性能挂钩
# 参考 可改成 ： processing_quantity = 10

is_head = True # 是否有头，True代表有头，False代表无头

operation_steps = [1,1,1] # 分别对应‘爬取链接’，‘解析链接’，‘最终处理’， 1对应进行该步骤，0代表不进行

# ——————————————————————————————————————————————————————
```
